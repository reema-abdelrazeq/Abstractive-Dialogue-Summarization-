{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6004344,"sourceType":"datasetVersion","datasetId":3438844}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Goal: Fine-tune a pre-trained language model to generate high-quality abstractive summaries using the SAMSum dataset.**\n\n**Dataset: The SAMSum dataset consists of conversational dialogues and corresponding concise summaries. It is particularly challenging due to the informal and context-rich nature of the dialogues, requiring models to generate accurate summaries.**\n","metadata":{}},{"cell_type":"markdown","source":"# **Step 1: Import Libraries**","metadata":{}},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments\nimport pandas as pd\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-12-05T17:05:05.013529Z","iopub.execute_input":"2024-12-05T17:05:05.013777Z","iopub.status.idle":"2024-12-05T17:05:22.876410Z","shell.execute_reply.started":"2024-12-05T17:05:05.013748Z","shell.execute_reply":"2024-12-05T17:05:22.875673Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# **Step 2: Loading the Dataset**\n> **I am going to load the dataset and explore its structure**\n","metadata":{}},{"cell_type":"code","source":"# Load dataset files\ntrain_data = pd.read_csv(\"/kaggle/input/samsum-dataset-text-summarization/samsum-train.csv\")\nval_data = pd.read_csv(\"/kaggle/input/samsum-dataset-text-summarization/samsum-validation.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/samsum-dataset-text-summarization/samsum-test.csv\")\n\n# Check a sample\ntrain_data.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:05:22.878070Z","iopub.execute_input":"2024-12-05T17:05:22.878605Z","iopub.status.idle":"2024-12-05T17:05:23.164693Z","shell.execute_reply.started":"2024-12-05T17:05:22.878577Z","shell.execute_reply":"2024-12-05T17:05:23.163839Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"         id                                           dialogue  \\\n0  13818513  Amanda: I baked  cookies. Do you want some?\\r\\...   \n1  13728867  Olivia: Who are you voting for in this electio...   \n2  13681000  Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...   \n3  13730747  Edward: Rachel, I think I'm in ove with Bella....   \n4  13728094  Sam: hey  overheard rick say something\\r\\nSam:...   \n\n                                             summary  \n0  Amanda baked cookies and will bring Jerry some...  \n1  Olivia and Olivier are voting for liberals in ...  \n2  Kim may try the pomodoro technique recommended...  \n3  Edward thinks he is in love with Bella. Rachel...  \n4  Sam is confused, because he overheard Rick com...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dialogue</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13818513</td>\n      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n      <td>Amanda baked cookies and will bring Jerry some...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13728867</td>\n      <td>Olivia: Who are you voting for in this electio...</td>\n      <td>Olivia and Olivier are voting for liberals in ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13681000</td>\n      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n      <td>Kim may try the pomodoro technique recommended...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13730747</td>\n      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n      <td>Edward thinks he is in love with Bella. Rachel...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13728094</td>\n      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n      <td>Sam is confused, because he overheard Rick com...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"# Observations\n* **Dialogue:\nText format includes speaker labels (e.g., \"Amanda:\" and \"Sam:\").\nThe dialogues are multiline (e.g., separated by \\r\\n) and have natural conversational flow thats why in the preprocessing i removed the whitespaces and the lines .**\n* **Summary:\nSummaries appear concise and relevant to the dialogues.\nThey seem to capture the core information in one or two sentences**\n","metadata":{}},{"cell_type":"code","source":"# to minimize training time i will use only a smaple\ntrain_data = train_data.sample(n=4000,random_state=42).reset_index(drop=True)\nval_data = val_data.sample(n=500, random_state=42).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:05:23.165911Z","iopub.execute_input":"2024-12-05T17:05:23.166635Z","iopub.status.idle":"2024-12-05T17:05:23.176807Z","shell.execute_reply.started":"2024-12-05T17:05:23.166595Z","shell.execute_reply":"2024-12-05T17:05:23.176012Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# **Step 3: Preparing the Data (Preprocess &Tokenization)**\n> Preprocessing ensures the dialogues and summaries are properly tokenized and truncated.\n> I  will use the Facebook BART-large model, as it's well-suited for summarization tasks:\n","metadata":{}},{"cell_type":"code","source":"#drop null values\ntrain_data = train_data.dropna()\nval_data = val_data.dropna()\ntest_data = test_data.dropna()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:05:23.177752Z","iopub.execute_input":"2024-12-05T17:05:23.178056Z","iopub.status.idle":"2024-12-05T17:05:23.190452Z","shell.execute_reply.started":"2024-12-05T17:05:23.178029Z","shell.execute_reply":"2024-12-05T17:05:23.189714Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import re\n# Preprocessing function to clean the text\ndef preprocess_text(text):\n    text = re.sub(r'\\r\\n', ' ', text)  # Remove carriage returns and line breaks\n    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n    text = re.sub(r'<.*?>', '', text)  # Remove any XML tags\n    text = text.strip().lower()  # Strip and convert to lower case\n    return text\n\n# Apply preprocessing to both dialogue and summary columns\ntrain_data[\"dialogue\"] = train_data[\"dialogue\"].apply(preprocess_text)\ntrain_data[\"summary\"] = train_data[\"summary\"].apply(preprocess_text)\n\nval_data[\"dialogue\"] = val_data[\"dialogue\"].apply(preprocess_text)\nval_data[\"summary\"] = val_data[\"summary\"].apply(preprocess_text)\n\ntest_data[\"dialogue\"] = test_data[\"dialogue\"].apply(preprocess_text)\ntest_data[\"summary\"] = test_data[\"summary\"].apply(preprocess_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:05:23.191476Z","iopub.execute_input":"2024-12-05T17:05:23.191724Z","iopub.status.idle":"2024-12-05T17:05:23.436710Z","shell.execute_reply.started":"2024-12-05T17:05:23.191701Z","shell.execute_reply":"2024-12-05T17:05:23.435698Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Check for any empty or missing values after preprocessing\nprint(f\"Empty dialogues in train data: {train_data['dialogue'].isnull().sum()}\")\nprint(f\"Empty summaries in train data: {train_data['summary'].isnull().sum()}\")\nprint(f\"Empty dialogues in validation data: {val_data['dialogue'].isnull().sum()}\")\nprint(f\"Empty summaries in validation data: {val_data['summary'].isnull().sum()}\")\nprint(f\"Empty dialogues in test data: {test_data['dialogue'].isnull().sum()}\")\nprint(f\"Empty summaries in test data: {test_data['summary'].isnull().sum()}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:05:23.437787Z","iopub.execute_input":"2024-12-05T17:05:23.438041Z","iopub.status.idle":"2024-12-05T17:05:23.445808Z","shell.execute_reply.started":"2024-12-05T17:05:23.438018Z","shell.execute_reply":"2024-12-05T17:05:23.444944Z"}},"outputs":[{"name":"stdout","text":"Empty dialogues in train data: 0\nEmpty summaries in train data: 0\nEmpty dialogues in validation data: 0\nEmpty summaries in validation data: 0\nEmpty dialogues in test data: 0\nEmpty summaries in test data: 0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Check some random samples from the cleaned data\nprint(\"Sample Dialogue (Train):\", train_data.loc[0, \"dialogue\"])\nprint(\"Sample Summary (Train):\", train_data.loc[0, \"summary\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:05:23.449096Z","iopub.execute_input":"2024-12-05T17:05:23.449455Z","iopub.status.idle":"2024-12-05T17:05:23.459928Z","shell.execute_reply.started":"2024-12-05T17:05:23.449428Z","shell.execute_reply":"2024-12-05T17:05:23.459153Z"}},"outputs":[{"name":"stdout","text":"Sample Dialogue (Train): violet: hi! i came across this austin's article and i thought that you might find it interesting violet:  claire: hi! :) thanks, but i've already read it. :) claire: but thanks for thinking about me :)\nSample Summary (Train): violet sent claire austin's article.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Check the number of rows in each dataset\nprint(f\"Training data size: {len(train_data)}\")\nprint(f\"Validation data size: {len(val_data)}\")\nprint(f\"Test data size: {len(test_data)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:05:23.460688Z","iopub.execute_input":"2024-12-05T17:05:23.460898Z","iopub.status.idle":"2024-12-05T17:05:23.470570Z","shell.execute_reply.started":"2024-12-05T17:05:23.460876Z","shell.execute_reply":"2024-12-05T17:05:23.469844Z"}},"outputs":[{"name":"stdout","text":"Training data size: 4000\nValidation data size: 500\nTest data size: 819\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Load the tokenizer\ntokenizer = T5Tokenizer.from_pretrained('t5-small')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:05:23.471375Z","iopub.execute_input":"2024-12-05T17:05:23.471596Z","iopub.status.idle":"2024-12-05T17:05:24.813803Z","shell.execute_reply.started":"2024-12-05T17:05:23.471575Z","shell.execute_reply":"2024-12-05T17:05:24.813107Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8eebf56ad03144ea9f96abfd7cc6569d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79961648fd874487ad658e49c3d4df93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffcfc1c20b1141d682a9546072db3082"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#  function for tokenization\ndef tokenize_data(examples):\n    # Tokenize the dialogue and summary\n    inputs = tokenizer(examples[\"dialogue\"], padding=\"max_length\", truncation=True, max_length=512)\n    targets = tokenizer(examples[\"summary\"], padding=\"max_length\", truncation=True, max_length=150)\n    inputs[\"labels\"] = targets[\"input_ids\"]\n    return inputs\n    \n # Tokenize train, validation, and test datasets\ntrain_dataset = train_data.apply(tokenize_data, axis=1)\nval_dataset = val_data.apply(tokenize_data, axis=1)\ntest_dataset=test_data.apply(tokenize_data,axis=1)\n\n# Check a tokenized sample\ntrain_dataset [0]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:05:24.814854Z","iopub.execute_input":"2024-12-05T17:05:24.815121Z","iopub.status.idle":"2024-12-05T17:05:28.837925Z","shell.execute_reply.started":"2024-12-05T17:05:24.815096Z","shell.execute_reply":"2024-12-05T17:05:28.837076Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [25208, 10, 7102, 55, 3, 23, 764, 640, 48, 403, 17, 77, 31, 7, 1108, 11, 3, 23, 816, 24, 25, 429, 253, 34, 1477, 25208, 10, 3, 7997, 15, 10, 7102, 55, 3, 10, 61, 2049, 6, 68, 3, 23, 31, 162, 641, 608, 34, 5, 3, 10, 61, 3, 7997, 15, 10, 68, 2049, 21, 1631, 81, 140, 3, 10, 61, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [25208, 1622, 3, 7997, 15, 403, 17, 77, 31, 7, 1108, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# **Step 4:Fine-Tune T5 Transformer**\n\n","metadata":{}},{"cell_type":"code","source":"# Load the pre-trained model\nmodel = T5ForConditionalGeneration.from_pretrained('t5-small')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:05:28.839089Z","iopub.execute_input":"2024-12-05T17:05:28.839468Z","iopub.status.idle":"2024-12-05T17:05:30.849072Z","shell.execute_reply.started":"2024-12-05T17:05:28.839430Z","shell.execute_reply":"2024-12-05T17:05:30.848180Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46b07ef3a5084c0a873d270b958094bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d103283b937415db19fb05ee0dc7211"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23e4c0b733764ef8bd96abf2dd51bff6"}},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# **Define Training Arguments**","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",          # output directory for checkpoints\n    num_train_epochs=6,              # number of training epochs\n    per_device_train_batch_size=8,   # batch size per device during training\n    per_device_eval_batch_size=8,    # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,               # strength of weight decay\n    logging_dir=\"./logs\",            # directory for storing logs\n    logging_steps=50,                # how often to log training info\n    save_steps=500,                  # how often to save a model checkpoint\n    eval_steps=50,                   # how often to run evaluation\n    eval_strategy=\"epoch\",     # Ensure evaluation happens every `epoch`\n    report_to=\"none\"\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:05:30.850348Z","iopub.execute_input":"2024-12-05T17:05:30.850694Z","iopub.status.idle":"2024-12-05T17:05:30.940330Z","shell.execute_reply.started":"2024-12-05T17:05:30.850658Z","shell.execute_reply":"2024-12-05T17:05:30.939392Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# **Step 5: Trainer Setup & Training the Model**","metadata":{}},{"cell_type":"code","source":"# Setup the trainer\ntrainer = Trainer(\n    model=model, \n    args=training_args, \n    train_dataset=train_dataset, \n    eval_dataset=val_dataset\n)\n\n# Print details for verification\nprint(\"Training configuration set up successfully!\")\nprint(\"Output directory:\", training_args.output_dir)\nprint(\"Number of training epochs:\", training_args.num_train_epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:05:30.941478Z","iopub.execute_input":"2024-12-05T17:05:30.941762Z","iopub.status.idle":"2024-12-05T17:05:31.204813Z","shell.execute_reply.started":"2024-12-05T17:05:30.941734Z","shell.execute_reply":"2024-12-05T17:05:31.203823Z"},"_kg_hide-output":true},"outputs":[{"name":"stdout","text":"Training configuration set up successfully!\nOutput directory: ./results\nNumber of training epochs: 6\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Start the training process\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:05:31.205855Z","iopub.execute_input":"2024-12-05T17:05:31.206156Z","iopub.status.idle":"2024-12-05T17:17:09.829143Z","shell.execute_reply.started":"2024-12-05T17:05:31.206129Z","shell.execute_reply":"2024-12-05T17:17:09.828068Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3000/3000 11:36, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.424600</td>\n      <td>0.380310</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.378400</td>\n      <td>0.359477</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.371100</td>\n      <td>0.354424</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.363100</td>\n      <td>0.349908</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.350000</td>\n      <td>0.348632</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.353400</td>\n      <td>0.348830</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3000, training_loss=0.9062748317718505, metrics={'train_runtime': 697.3754, 'train_samples_per_second': 34.415, 'train_steps_per_second': 4.302, 'total_flos': 3248203235328000.0, 'train_loss': 0.9062748317718505, 'epoch': 6.0})"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"# **Step 6: Save and load model**","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(\"./final_model\")\ntokenizer.save_pretrained(\"./final_model\")\n","metadata":{"trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-12-05T17:20:04.763997Z","iopub.execute_input":"2024-12-05T17:20:04.764387Z","iopub.status.idle":"2024-12-05T17:20:05.316875Z","shell.execute_reply.started":"2024-12-05T17:20:04.764355Z","shell.execute_reply":"2024-12-05T17:20:05.316000Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"('./final_model/tokenizer_config.json',\n './final_model/special_tokens_map.json',\n './final_model/spiece.model',\n './final_model/added_tokens.json')"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# Load the saved model and tokenizer\nmodel = T5ForConditionalGeneration.from_pretrained(\"./final_model\")\ntokenizer = T5Tokenizer.from_pretrained(\"./final_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:26:04.798174Z","iopub.execute_input":"2024-12-05T17:26:04.798938Z","iopub.status.idle":"2024-12-05T17:26:05.227548Z","shell.execute_reply.started":"2024-12-05T17:26:04.798896Z","shell.execute_reply":"2024-12-05T17:26:05.226747Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"**test the summarization system**","metadata":{}},{"cell_type":"code","source":"device = model.device  # Get the device the model is on\n\ndef summarize_dialogue(dialogue):\n    dialogue = preprocess_text(dialogue)  \n    inputs = tokenizer(dialogue, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n    \n    # Move input tensors to the same device as the model\n    inputs = {key: value.to(device) for key, value in inputs.items()}\n\n    # Generate summary\n    outputs = model.generate(\n        inputs[\"input_ids\"], \n        max_length=150,  \n        num_beams=4, \n        early_stopping=True\n    )\n    \n    # Decode the generated summary\n    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:28:42.924915Z","iopub.execute_input":"2024-12-05T17:28:42.925659Z","iopub.status.idle":"2024-12-05T17:28:42.931241Z","shell.execute_reply.started":"2024-12-05T17:28:42.925624Z","shell.execute_reply":"2024-12-05T17:28:42.930347Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"sample_dialogue = \"\"\"\nSarah: \"I’ve been thinking about moving to a new city for a while now. I feel like I need a change of scenery, you know? I’ve been stuck in this routine for so long.\"\nJessica: \"I get that. A fresh start can be really refreshing. Have you thought about where you might want to go?\"\nSarah: \"I’ve been looking into a few places. New York is obviously on my list. The energy there is unmatched, but I’m also considering somewhere a bit quieter, like Portland or Austin. I like the idea of being in a city with a strong arts scene, but I don’t want it to be too fast-paced.\"\nJessica: \"I think both Portland and Austin sound like great options. Portland has such a laid-back vibe, and it’s surrounded by nature. You can easily go hiking or take weekend trips to the coast. Austin, on the other hand, is known for its tech scene and live music, so you’d never be bored.\"\nSarah: \"Yeah, that’s true. I just want a place where I feel inspired and can grow both personally and professionally. I’m also trying to figure out if I can find a job that fits what I want to do.\"\nJessica: \"That’s a big part of it too. Finding the right balance between work and lifestyle is key. Have you looked into remote jobs? That could give you more flexibility in terms of location.\"\nSarah: \"I have, actually! I’ve been exploring some remote opportunities in the tech industry. It’s definitely something I’m leaning toward.\"\nJessica: \"That sounds perfect for you. It’ll give you the freedom to live wherever you want and still have a great career.\"\nSarah: \"Exactly. I think I’m just about ready to make the move. Now I just need to start narrowing down my options and figuring out the logistics.\"\nJessica: \"You’ve got this! I’m sure whatever city you choose will be a great fit.\"\n\"\"\"\nsummary = summarize_dialogue(sample_dialogue)\nprint(\"Summary:\", summary)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:35:44.800652Z","iopub.execute_input":"2024-12-05T17:35:44.801020Z","iopub.status.idle":"2024-12-05T17:35:46.851590Z","shell.execute_reply.started":"2024-12-05T17:35:44.800989Z","shell.execute_reply":"2024-12-05T17:35:46.850630Z"}},"outputs":[{"name":"stdout","text":"Summary: sarah has been thinking about moving to a new city for a while now. jessica is considering a place quieter, like portland and austin.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"sample_dialogue = \"\"\"\nTom: \"I’ve been struggling with managing my time lately. Work has been really demanding, and I’ve been finding it hard to balance everything else in my life. Do you ever feel like that?\"\nRachel: \"Oh, absolutely. It’s tough, especially when there are so many things pulling you in different directions. What do you usually do to manage it all?\"\nTom: \"I try to stay organized, but sometimes it feels like there’s just too much to do. I use a calendar and set reminders, but I still miss deadlines or feel like I’m not putting enough time into the things that matter outside of work.\"\nRachel: \"I think it’s easy to get caught up in work. I used to have the same problem, but I’ve been trying to set clearer boundaries between work and personal time. For instance, I no longer check my work emails after 7 PM.\"\nTom: \"That’s a good idea. I think I need to start doing that. The problem is, there’s always something that needs to be done, so it’s hard to just let go sometimes.\"\nRachel: \"I get it. But if you keep pushing yourself without taking breaks, it’ll burn you out. I also started incorporating little things throughout the day to recharge, like going for a walk or reading a chapter of a book. It helps clear my mind.\"\nTom: \"I haven’t been taking enough breaks, honestly. I just go from task to task, and it feels like I’m constantly running on empty. Maybe I should try some of the things you’re doing.\"\nRachel: \"Definitely! And another thing that’s helped me is learning to say ‘no’ to things that I don’t have the energy for. It’s hard at first, but it’s freeing.\"\nTom: \"Yeah, I think I need to work on that too. I always feel guilty about not helping out or taking on extra work, but I guess it’s important to prioritize my own well-being.\"\nRachel: \"Exactly. You can’t be your best for others if you’re not taking care of yourself first. It’s all about finding that balance.\"\nTom: \"Thanks for the advice, Rachel. I’m definitely going to try some of these strategies.\"\nRachel: \"You’re welcome! I’m sure you’ll feel a lot better once you start making those changes.\"\n\"\"\"\nsummary = summarize_dialogue(sample_dialogue)\nprint(\"Summary:\", summary)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:36:34.294972Z","iopub.execute_input":"2024-12-05T17:36:34.295411Z","iopub.status.idle":"2024-12-05T17:36:36.596985Z","shell.execute_reply.started":"2024-12-05T17:36:34.295375Z","shell.execute_reply":"2024-12-05T17:36:36.596034Z"}},"outputs":[{"name":"stdout","text":"Summary: tom has been struggling with managing his time lately. rachel has been trying to balance everything else in her life. rachel has started incorporating little things throughout the day to recharge, like going for a walk or reading a book.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"sample_dialogue = \"\"\"\nMark: \"I’ve been really into learning about personal finance lately. I think it’s something I should have paid more attention to earlier in life, you know?\"\nLucas: \"I totally agree. I didn’t really start understanding how important it is until a few years ago. Have you been reading up on budgeting or investing?\"\nMark: \"A bit of both. I’ve been using an app to track my spending and see where I can cut back, but I’m also really interested in investing for the long term. I’ve been trying to get into stocks and maybe even real estate.\"\nLucas: \"That’s great. A lot of people don’t start thinking about investing until later on, so it’s good that you’re getting ahead of it. What have you learned about stocks so far?\"\nMark: \"Well, I’ve been reading about the stock market and trying to understand different strategies, like value investing and growth investing. I’m also starting small with index funds to minimize risk.\"\nLucas: \"That’s smart. Index funds are a great way to get exposure to the market without having to pick individual stocks. I’ve been doing the same thing, but I’m also trying to learn more about cryptocurrency.\"\nMark: \"I’ve heard a lot about crypto, but I’m a little cautious. It seems so volatile, and I don’t want to risk too much, especially when I’m just starting.\"\nLucas: \"That’s understandable. Crypto is definitely risky, but it can also be a great opportunity for growth if you’re able to handle the ups and downs. I think the key is only investing what you’re willing to lose.\"\nMark: \"I agree. I’ll probably stay conservative for now and stick to traditional investments, but it’s good to know more about crypto in case I decide to dive in later.\"\nLucas: \"Exactly. Just keep learning and making informed decisions. And don’t forget about the importance of saving too—having an emergency fund is key.\"\nMark: \"Definitely. I’m working on building that up as well. I want to have a solid financial foundation before making any big moves.\"\nLucas: \"Sounds like you’re on the right track. Keep it up!\"\n\"\"\"\nsummary = summarize_dialogue(sample_dialogue)\nprint(\"Summary:\", summary)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-05T17:37:27.036176Z","iopub.execute_input":"2024-12-05T17:37:27.036637Z","iopub.status.idle":"2024-12-05T17:37:29.114485Z","shell.execute_reply.started":"2024-12-05T17:37:27.036605Z","shell.execute_reply":"2024-12-05T17:37:29.113513Z"}},"outputs":[{"name":"stdout","text":"Summary: lucas has been learning about personal finance lately. lucas has been using an app to track his spending and see where he can cut back. lucas is starting small with index funds to minimize risk.\n","output_type":"stream"}],"execution_count":26}]}